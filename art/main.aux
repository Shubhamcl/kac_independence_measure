\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Gretton2005MeasuringSD}
\citation{EigenHSIC}
\citation{HSCA}
\citation{Ma2020TheHB}
\citation{NIPS2008_f7664060}
\citation{li2021selfsupervised}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{Cover2006}
\citation{Gretton2005MeasuringSD}
\citation{Feuerverger}
\citation{Szekely}
\citation{Pczos2012CopulabasedKD}
\citation{NIPS2019_9147}
\citation{Feuerverger}
\citation{Szekely}
\citation{Szekely}
\citation{Bottcher}
\citation{Szekely}
\@writefile{toc}{\contentsline {section}{\numberline {2}Previous Work}{2}{section.2}}
\newlabel{section:previous_work}{{2}{2}{Previous Work}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Characteristic-function-based methods}{2}{subsection.2.1}}
\newlabel{section:previous_work_cf}{{2.1}{2}{Characteristic-function-based methods}{subsection.2.1}{}}
\newlabel{eq:characteristic_function}{{1}{2}{Characteristic-function-based methods}{equation.2.1}{}}
\newlabel{eq:ecf}{{2}{2}{Characteristic-function-based methods}{equation.2.2}{}}
\newlabel{eq:joint_characteristic_function}{{3}{2}{Characteristic-function-based methods}{equation.2.3}{}}
\newlabel{eq:joint_ecf}{{4}{2}{Characteristic-function-based methods}{equation.2.4}{}}
\citation{Szekely}
\citation{Edlemann}
\citation{Jacod}
\citation{KacTheorem}
\newlabel{eq:kac_theorem}{{5}{3}{Characteristic-function-based methods}{equation.2.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Proposed Independence Measure}{3}{section.3}}
\newlabel{section:proposed_method}{{3}{3}{Proposed Independence Measure}{section.3}{}}
\newlabel{eq:kim}{{6}{3}{Proposed Independence Measure}{equation.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Properties}{3}{subsection.3.1}}
\newlabel{thm:properties}{{1}{3}{}{theorem.1}{}}
\citation{NEURIPS2019_9015}
\citation{Loshchilov2019DecoupledWD}
\citation{10.5555/3279302}
\citation{?}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Estimation}{4}{subsection.3.2}}
\newlabel{eq:estimator}{{7}{4}{Estimation}{equation.3.7}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces KacIM estimation iteration\relax }}{4}{algorithm.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:estimator_computation}{{1}{4}{KacIM estimation iteration\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Kernel version}{4}{subsection.3.3}}
\newlabel{eq:kernel_estimator}{{8}{4}{Kernel version}{equation.3.8}{}}
\newlabel{eq:kernel_estimator1}{{9}{4}{Kernel version}{equation.3.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Left figure: Dependence detection in independent data (blue), additive (orange) and multiplicative (green) noise scenarios. Righ figure: noise level ($x$ axis) vs final iteration KacIM value ($y$ axis). KacIM values for larger noise levels saturates as in tail of graph\relax }}{5}{figure.caption.2}}
\newlabel{fig:experiments_simulation}{{1}{5}{Left figure: Dependence detection in independent data (blue), additive (orange) and multiplicative (green) noise scenarios. Righ figure: noise level ($x$ axis) vs final iteration KacIM value ($y$ axis). KacIM values for larger noise levels saturates as in tail of graph\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{5}{section.4}}
\newlabel{section:experiments}{{4}{5}{Experiments}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Generated data}{5}{subsection.4.1}}
\@writefile{toc}{\contentsline {paragraph}{Non-linear statistical dependence detection.}{5}{section*.1}}
\citation{OpenML2013}
\citation{NIPS2004_42fe8808}
\@writefile{toc}{\contentsline {paragraph}{Noise variance effect}{6}{section*.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Feature selection}{6}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Feature extraction}{6}{subsection.4.3}}
\newlabel{eq:kim_feature_extraction}{{10}{6}{Feature extraction}{equation.4.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Regularisation}{6}{subsection.4.4}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Classification accuracies. $N$ denotes full data set size, $d_{x}$ - input dimensionality, and $n_{c}$ - number of classes. \relax }}{7}{table.caption.4}}
\newlabel{table:classification_accuracies}{{1}{7}{Classification accuracies. $N$ denotes full data set size, $d_{x}$ - input dimensionality, and $n_{c}$ - number of classes. \relax }{table.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Classification accuracy comparison of regularised and not regularised model (pneumonia dataset). \relax }}{7}{table.caption.5}}
\newlabel{table:regularisation_classification_accuracies}{{2}{7}{Classification accuracy comparison of regularised and not regularised model (pneumonia dataset). \relax }{table.caption.5}{}}
\bibstyle{unsrt}
\bibdata{bibliography}
\bibcite{Gretton2005MeasuringSD}{1}
\bibcite{EigenHSIC}{2}
\bibcite{HSCA}{3}
\bibcite{Ma2020TheHB}{4}
\bibcite{NIPS2008_f7664060}{5}
\bibcite{li2021selfsupervised}{6}
\bibcite{Cover2006}{7}
\bibcite{Feuerverger}{8}
\bibcite{Szekely}{9}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{8}{section.5}}
\newlabel{section:conclusion}{{5}{8}{Conclusion}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Acknowledgements}{8}{section.6}}
\bibcite{Pczos2012CopulabasedKD}{10}
\bibcite{NIPS2019_9147}{11}
\bibcite{Bottcher}{12}
\bibcite{Edlemann}{13}
\bibcite{Jacod}{14}
\bibcite{KacTheorem}{15}
\bibcite{NEURIPS2019_9015}{16}
\bibcite{Loshchilov2019DecoupledWD}{17}
\bibcite{10.5555/3279302}{18}
\bibcite{OpenML2013}{19}
\bibcite{NIPS2004_42fe8808}{20}
