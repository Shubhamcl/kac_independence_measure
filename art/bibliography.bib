@article{Feuerverger,
 ISSN = {03067734, 17515823},
 URL = {http://www.jstor.org/stable/1403753},
 abstract = {A new and consistent rank test for bivariate dependence is developed. Let Xi ′ and Yi ′ denote the (approximate) normal scores associated with the iid vectors (Xi,Yi),i=1,... ,n. Then the proposed test statistic may be obtained by removing the first Hájek projection from the quantity $\xi \equiv n^{-2}\mathop{\sum\sum}|X_{j}^{\prime}-X_{k}^{\prime}|\cdot |Y_{j}^{\prime}-Y_{k}^{\prime}|$. Empirical characteristic function considerations are used in our development and some related graphical methods are proposed. Some difficulties that arise in extensions to dimension k > 2 are noted. A small simulation study provides evidence of the effectiveness of the new procedure. /// Un nouveau test du rank convergent pour la dépendance bivariée est exposé dans cet article. Soit Xi ′ et Yi ′ les scores normaux (approchés) associés aux vecteurs iid (Xi,Yi),i=1,... ,n. La statistique du test proposée peut alors être obtenue en enlevant la première projection de Hájek de la quantité $\xi =n^{-2}\mathop{\sum\sum}|X_{j}^{\prime}-X_{k}^{\prime}|\cdot |Y_{i}^{\prime}-Y_{k}^{\prime}|$. Des considérations liées aux fonctions caractéristiques empiriques sont utilisées dans notre développement et des méthodes graphiques correspondantes sont proposées. Des difficultés apparaissant lors d'extensions aux dimensions k > 2 sont indiquées. Une étude de simulation atteste de l'efficacité de la nouvelle méthode.},
 author = {Andrey Feuerverger},
 journal = {International Statistical Review / Revue Internationale de Statistique},
 number = {3},
 pages = {419--433},
 publisher = {[Wiley, International Statistical Institute (ISI)]},
 title = {A Consistent Test for Bivariate Dependence},
 volume = {61},
 year = {1993}
}

@article{KacTheorem,
author = 'David Applebaum, B.V. Rajarama Bhat, Johan Kustermans, J. Martin Lindsay, Michael Schuermann, Uwe Franz',
title = 'Quantum Independent Increment Processes I: From Classical Probability to Quantum Stochastic Calculus'
}

@unknown{Bottcher,
author = {Böttcher, Björn and Keller-Ressel, Martin and Schilling, René},
year = {2018},
month = {10},
pages = {},
title = {Distance multivariance: New dependence measures for random vectors}
}

@inproceedings{Belu2012MultivariateMO,
  title={Multivariate measures of dependence for random variables and Levy processes},
  author={Alexandru Belu},
  year={2012}
}

@article{Szekely,
author = {Gábor J. Székely and Maria L. Rizzo and Nail K. Bakirov},
title = {{Measuring and testing dependence by correlation of distances}},
volume = {35},
journal = {The Annals of Statistics},
number = {6},
publisher = {Institute of Mathematical Statistics},
pages = {2769 -- 2794},
keywords = {Distance correlation, distance covariance, multivariate independence},
year = {2007},
doi = {10.1214/009053607000000505},
URL = {https://doi.org/10.1214/009053607000000505}
}

@inproceedings{Gretton2005MeasuringSD,
  title={Measuring Statistical Dependence with Hilbert-Schmidt Norms},
  author={Arthur Gretton and Olivier Bousquet and Alex Smola and Bernhard Sch{\"o}lkopf},
  booktitle={ALT},
  year={2005}
}

@book{Cover2006,
  added-at = {2009-04-20T21:27:16.000+0200},
  at = {2008-03-31 06:17:47},
  author = {Cover, Thomas M. and Thomas, Joy A.},
  biburl = {https://www.bibsonomy.org/bibtex/22e9bfa879286689a14feb55b69d326c1/ywhuang},
  howpublished = {Hardcover},
  id = {1877660},
  interhash = {87ae368776946bf7a71ee476e81a2191},
  intrahash = {2e9bfa879286689a14feb55b69d326c1},
  isbn = {0471241954},
  keywords = {information-theory book},
  month = {July},
  priority = {0},
  publisher = {Wiley-Interscience},
  timestamp = {2009-04-20T21:27:16.000+0200},
  title = {Elements of Information Theory 2nd Edition (Wiley Series in Telecommunications and Signal Processing)},
  year = 2006
}


@Article{e20110813,
AUTHOR = {Amigó, José M. and Balogh, Sámuel G. and Hernández, Sergio},
TITLE = {A Brief Review of Generalized Entropies},
JOURNAL = {Entropy},
VOLUME = {20},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {813},
URL = {https://www.mdpi.com/1099-4300/20/11/813},
ISSN = {1099-4300},
ABSTRACT = {Entropy appears in many contexts (thermodynamics, statistical mechanics, information theory, measure-preserving dynamical systems, topological dynamics, etc.) as a measure of different properties (energy that cannot produce work, disorder, uncertainty, randomness, complexity, etc.). In this review, we focus on the so-called generalized entropies, which from a mathematical point of view are nonnegative functions defined on probability distributions that satisfy the first three Shannon&ndash;Khinchin axioms: continuity, maximality and expansibility. While these three axioms are expected to be satisfied by all macroscopic physical systems, the fourth axiom (separability or strong additivity) is in general violated by non-ergodic systems with long range forces, this having been the main reason for exploring weaker axiomatic settings. Currently, non-additive generalized entropies are being used also to study new phenomena in complex dynamics (multifractality), quantum systems (entanglement), soft sciences, and more. Besides going through the axiomatic framework, we review the characterization of generalized entropies via two scaling exponents introduced by Hanel and Thurner. In turn, the first of these exponents is related to the diffusion scaling exponent of diffusion processes, as we also discuss. Applications are addressed as the description of the main generalized entropies advances.},
DOI = {10.3390/e20110813}
}

@article{Pczos2012CopulabasedKD,
  title={Copula-based Kernel Dependency Measures},
  author={Barnab{\'a}s P{\'o}czos and Zoubin Ghahramani and Jeff G. Schneider},
  journal={ArXiv},
  year={2012},
  volume={abs/1206.4682}
}

@article{Szkely2013PartialDC,
  title={Partial Distance Correlation with Methods for Dissimilarities},
  author={G{\'a}bor J. Sz{\'e}kely and Maria L. Rizzo},
  journal={arXiv: Methodology},
  year={2013}
}

@inproceedings{Loshchilov2019DecoupledWD,
  title={Decoupled Weight Decay Regularization},
  author={Ilya Loshchilov and Frank Hutter},
  booktitle={ICLR},
  year={2019}
}

@inproceedings{NIPS2008_f7664060,
 author = {Hoyer, Patrik and Janzing, Dominik and Mooij, Joris M and Peters, Jonas and Sch\"{o}lkopf, Bernhard},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Koller and D. Schuurmans and Y. Bengio and L. Bottou},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Nonlinear causal discovery with additive noise models},
 url = {https://proceedings.neurips.cc/paper/2008/file/f7664060cc52bc6f3d620bcedc94a4b6-Paper.pdf},
 volume = {21},
 year = {2009}
}

@InProceedings{EigenHSIC,
author="Daniu{\v{s}}is, P.
and Vaitkus, P.",
editor="Corchado, Emilio
and Yin, Hujun",
title="Supervised Feature Extraction Using Hilbert-Schmidt Norms",
booktitle="Intelligent Data Engineering and Automated Learning - IDEAL 2009",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="25--33",
abstract="We propose a novel, supervised feature extraction procedure, based on an unbiased estimator of the Hilbert-Schmidt independence criterion (HSIC). The proposed procedure can be directly applied to single-label or multi-label data, also the kernelized version can be applied to any data type, on which a positive definite kernel function has been defined. Computer experiments with various classification data sets reveal that our approach can be applied more efficiently than the alternative ones.",
isbn="978-3-642-04394-9"
}

@book{10.5555/3279302,
author = {Schlkopf, Bernhard and Smola, Alexander J. and Bach, Francis},
title = {Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond},
year = {2018},
isbn = {0262536579},
publisher = {The MIT Press},
abstract = {A comprehensive introduction to Support Vector Machines and related kernel methods. In the 1990s, a new type of learning algorithm was developed, based on results from statistical learning theory: the Support Vector Machine (SVM). This gave rise to a new class of theoretically elegant learning machines that use a central concept of SVMs-kernelsfor a number of learning tasks. Kernel machines provide a modular framework that can be adapted to different tasks and domains by the choice of the kernel function and the base algorithm. They are replacing neural networks in a variety of fields, including engineering, information retrieval, and bioinformatics. Learning with Kernels provides an introduction to SVMs and related kernel methods. Although the book begins with the basics, it also includes the latest research. It provides all of the concepts necessary to enable a reader equipped with some basic mathematical knowledge to enter the world of machine learning using theoretically well-founded yet easy-to-use kernel algorithms and to understand and apply the powerful algorithms that have been developed over the last few years.}
}

@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@article{Ma2020TheHB,
  title={The HSIC Bottleneck: Deep Learning without Back-Propagation},
  author={Kurt Wan-Duo Ma and J. P. Lewis and W. Kleijn},
  journal={ArXiv},
  year={2020},
  volume={abs/1908.01580}
}